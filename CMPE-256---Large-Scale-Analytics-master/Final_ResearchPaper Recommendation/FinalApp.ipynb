{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [05/Aug/2019 19:08:22] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Aug/2019 19:08:23] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962714657\n",
      "fgggg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maulin.DESKTOP-L9C3L1C\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:106: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "127.0.0.1 - - [05/Aug/2019 19:08:37] \"POST /hello HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_id  5441 title  Optimal prevention with possibilistic and mixed background risk category  CE\n",
      "paper_id  5818 title  Hospital Case Cost Estimates Modelling - Algorithm Comparison category  CE\n",
      "paper_id  7062 title  Numerical extraction of a macroscopic pde and a lifting operator from a\n",
      "  lattice Boltzmann model category  CE\n",
      "paper_id  5593 title  Encoding Candlesticks as Images for Patterns Classification Using\n",
      "  Convolutional Neural Networks category  CE\n",
      "paper_id  7328 title  Dynamical Models of Stock Prices Based on Technical Trading Rules Part\n",
      "  I: The Models category  in.TR\n",
      "paper_id  5891 title  Efficient Dealiased Convolutions without Padding category  CE\n",
      "Neural Network\n",
      "ert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maulin.DESKTOP-L9C3L1C\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "127.0.0.1 - - [05/Aug/2019 19:10:55] \"POST /search HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The papers with search query are\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('new 1.html')\n",
    "\n",
    "@app.route('/hello', methods=['POST'])\n",
    "def hello():\n",
    "    \n",
    "    var = request.form['nm']\n",
    "    #last_name = request.form['last_name']\n",
    "    print(var)\n",
    "    tocsv(int(var))\n",
    "    return render_template('fr.html',first_name=var)\n",
    "\n",
    "\n",
    "@app.route('/search', methods=['POST'])\n",
    "def search():\n",
    "    \n",
    "    var = request.form['submit']\n",
    "    #last_name = request.form['last_name']\n",
    "    print(var)\n",
    "    function(var)\n",
    "    return render_template('fs.html',first_name=var)\n",
    "\n",
    "\n",
    "def function(query):\n",
    "\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    import pandas as pd\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    from collections import OrderedDict\n",
    "    import string\n",
    "\n",
    "    print(\"ert\")\n",
    "    with open('papers.pkl', 'rb') as f :\n",
    "        data = pickle.load(f)\n",
    "    cols = ['title']+ ['summary']\n",
    "    df_jobs =data[cols]\n",
    "    df_jobs.columns = ['title','summary']\n",
    "    df=df_jobs[:1000]\n",
    "    summary = df[:1000][\"summary\"]\n",
    "    summary_tokens = []\n",
    "    paper_list=[]\n",
    "\n",
    "\n",
    "    porter_stemmer = PorterStemmer()\n",
    "\n",
    "    def tokenize_query(q):\n",
    "        summ = [char for char in q if char not in string.punctuation]\n",
    "        summ = ''.join(summ)\n",
    "\n",
    "        word=[word for word in summ.split() if word.lower() not in\n",
    "stopwords.words('english')]\n",
    "        return [porter_stemmer.stem(word) for word in word]\n",
    "    query1 = tokenize_query(query)\n",
    "\n",
    "    def tokenize_summary(summary):\n",
    "        summ = [char for char in summary if char not in string.punctuation]\n",
    "        summ = ''.join(summ)\n",
    "\n",
    "        word=[word for word in summ.split() if word.lower() not in\n",
    "stopwords.words('english')]\n",
    "        return[porter_stemmer.stem(word) for word in word]\n",
    "\n",
    "\n",
    "\n",
    "    for i in df['summary']:\n",
    "        if len(i) > 10:\n",
    "            summary_tokens.append(tokenize_summary(i))\n",
    "\n",
    "    df['summary_tokens'] = pd.Series(summary_tokens)\n",
    "    diction = dict(zip(df.title, df.summary_tokens))\n",
    "\n",
    "\n",
    "    for key,value in diction.items():\n",
    "        for word in query1:\n",
    "            if word in value:\n",
    "                paper_list.append(key)\n",
    "\n",
    "    final_list=list(OrderedDict.fromkeys(paper_list))\n",
    "    final_list=final_list[:10]\n",
    "    print(\"The papers with search query are\")\n",
    "\n",
    "    def opcsv(print_list):\n",
    "        with open('static/search1.csv', 'w') as csvfile:\n",
    "            fieldnames = ['papers_title']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writeheader()\n",
    "            for title in print_list:\n",
    "                writer.writerow({'papers_title': title})\n",
    "\n",
    "    opcsv(final_list)\n",
    "    return final_list\n",
    "\n",
    "\n",
    "def tocsv(uid):\n",
    "    print(\"fgggg\")\n",
    "    with open('student_paper_mappings.pkl', 'rb') as f:\n",
    "        data_ref = pickle.load(f)\n",
    "        matrix=data_ref.as_matrix()\n",
    "        for index,i in enumerate(matrix):\n",
    "            matrix[index][0]=matrix[index][0].split(',')\n",
    "\n",
    "        arr=[]\n",
    "        for (index,it1) in enumerate(matrix):\n",
    "            arr.append([])\n",
    "            for it2 in matrix:\n",
    "\n",
    "                it1_set = set(it1[0])\n",
    "                it2_set = set(it2[0])\n",
    "                arr[index].append(it1_set & it2_set)\n",
    "        # set (i,i ) to empty set before finding most matched user\n",
    "        for (index,it) in enumerate(arr):\n",
    "            arr[index][index]=set()\n",
    "        # Arrays to maintain the most matched user, and no. of common papers\n",
    "        match=[0]*120\n",
    "        count=[0]*120\n",
    "        # for i, val in enumerate(arr):\n",
    "        #     print(i, val)\n",
    "        for (index1,it2) in enumerate(arr):\n",
    "            #print(it2)\n",
    "            for(index2,it2) in enumerate(it2):\n",
    "                #print(index1,index2)\n",
    "                a = len(arr[index1][index2])\n",
    "                #print(len(arr[index1][index2]))\n",
    "                if(count[index1]<len(arr[index1][index2])):\n",
    "                    match[index1]=index2\n",
    "                    count[index1]=len(arr[index1][index2])\n",
    "        for (index,i) in enumerate(match):\n",
    "            s=(set(matrix[i][0])-set(matrix[index][0]))\n",
    "        l=list(s)\n",
    "        cleanedList = [x for x in l if str(x) != 'nan']\n",
    "        cl = [int(i) for i in cleanedList]\n",
    "\n",
    "        with open('papers.pkl', 'rb') as f:\n",
    "            data_papers = pickle.load(f)\n",
    "        uid=list(data_ref.student_id).index(uid)\n",
    "        s=(set(matrix[match[uid]][0])-set(matrix[uid][0]))\n",
    "        l=list(s)\n",
    "        cleanedList = [x for x in l if str(x) != 'nan']\n",
    "        cl = [int(i) for i in cleanedList]\n",
    "        list_papers=[]\n",
    "        with open('static/user_rec1.csv','w') as csvfile:\n",
    "            fieldnames=['paper_id','title','category']\n",
    "            writer=csv.DictWriter(csvfile,fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for i in cl:\n",
    "                writer.writerow({'paper_id':i,'title':data_papers.title[i],'category':data_papers.arxiv_primary_category[i]})\n",
    "                list_papers.append(i)\n",
    "                #print(\"User ID \",uid)\n",
    "                print('paper_id ',i,'title ',data_papers.title[i],'category ',data_papers.arxiv_primary_category[i])\n",
    "\n",
    "#tocsv(621741617)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'IPython.lib' has no attribute 'dreload'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bd1bd3b49be2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdreload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'IPython.lib' has no attribute 'dreload'"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.lib.dreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
