{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_id  8844 title  Ontology for Mobile Phone Operating Systems category  SE\n",
      "paper_id  10156 title  Software Architecture Decision-Making Practices and Challenges: An\n",
      "  Industrial Case Study category  SE\n",
      "paper_id  8809 title  Examining the Impact of Platform Properties on Quality Attributes category  SE\n",
      "paper_id  8423 title  Software Components for Web Services category  SE\n",
      "paper_id  8823 title  Towards a better understanding of testing if conditionals category  SE\n",
      "paper_id  9784 title  Service-Oriented Architecture in Industrial Automation Systems - The\n",
      "  case of IEC 61499: A Review category  SE\n",
      "paper_id  11909 title  The Wall and The Ball: A Study of Domain Referent Spreadsheet Errors category  HC\n",
      "paper_id  8312 title  EuSpRIG 2006 Commercial Spreadsheet Review category  SE\n",
      "paper_id  9503 title  Hierarchical Variability Modeling for Software Architectures category  SE\n",
      "paper_id  10724 title  CrashScope: A Practical Tool for Automated Testing of Android\n",
      "  Applications category  SE\n",
      "paper_id  12333 title  HTTP Mailbox - Asynchronous RESTful Communication category  SE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tocsv(uid):\n",
    "    import pickle\n",
    "    import csv\n",
    "    with open('student_paper_mappings.pkl', 'rb') as f:\n",
    "        data_ref = pickle.load(f)\n",
    "        matrix=data_ref.as_matrix()\n",
    "        for index,i in enumerate(matrix):\n",
    "            matrix[index][0]=matrix[index][0].split(',')\n",
    "\n",
    "        arr=[]\n",
    "        for (index,it1) in enumerate(matrix):\n",
    "            arr.append([])\n",
    "            for it2 in matrix:\n",
    "\n",
    "                it1_set = set(it1[0])\n",
    "                it2_set = set(it2[0])\n",
    "                arr[index].append(it1_set & it2_set)\n",
    "        # set (i,i ) to empty set before finding most matched user\n",
    "        for (index,it) in enumerate(arr):\n",
    "            arr[index][index]=set()\n",
    "        # Arrays to maintain the most matched user, and no. of common papers\n",
    "        match=[0]*120\n",
    "        count=[0]*120\n",
    "        # for i, val in enumerate(arr):\n",
    "        #     print(i, val)\n",
    "        for (index1,it2) in enumerate(arr):\n",
    "            #print(it2)\n",
    "            for(index2,it2) in enumerate(it2):\n",
    "                #print(index1,index2)\n",
    "                a = len(arr[index1][index2])\n",
    "                #print(len(arr[index1][index2]))\n",
    "                if(count[index1]<len(arr[index1][index2])):\n",
    "                    match[index1]=index2\n",
    "                    count[index1]=len(arr[index1][index2])\n",
    "        for (index,i) in enumerate(match):\n",
    "            s=(set(matrix[i][0])-set(matrix[index][0]))\n",
    "        l=list(s)\n",
    "        cleanedList = [x for x in l if str(x) != 'nan']\n",
    "        cl = [int(i) for i in cleanedList]\n",
    "\n",
    "        with open('papers.pkl', 'rb') as f:\n",
    "            data_papers = pickle.load(f)\n",
    "        uid=list(data_ref.student_id).index(uid)\n",
    "        s=(set(matrix[match[uid]][0])-set(matrix[uid][0]))\n",
    "        l=list(s)\n",
    "        cleanedList = [x for x in l if str(x) != 'nan']\n",
    "        cl = [int(i) for i in cleanedList]\n",
    "        list_papers=[]\n",
    "        with open('user_rec.csv','w') as csvfile:\n",
    "            fieldnames=['paper_id','title','category']\n",
    "            writer=csv.DictWriter(csvfile,fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for i in cl:\n",
    "                writer.writerow({'paper_id':i,'title':data_papers.title[i],'category':data_papers.arxiv_primary_category[i]})\n",
    "                list_papers.append(i)\n",
    "                #print(\"User ID \",uid)\n",
    "                print('paper_id ',i,'title ',data_papers.title[i],'category ',data_papers.arxiv_primary_category[i])\n",
    "\n",
    "tocsv(621741617)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
